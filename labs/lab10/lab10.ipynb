{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wstęp do Uczenia Maszynowego \n",
    "##### Laboratorium 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Selekcja zmiennych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1\n",
    "----\n",
    "Przyjrzyj się dokumentacji funkcji `SelectFromModel()`. Wczytaj zbiór danych `SAheart.data`, podziel na zbiór treningowy i testowy w stosunku 3:2.\n",
    "\n",
    "a) Przygotuj `pipeline`, który przygotuje model regresji logistycznej.\n",
    "\n",
    "b) Dodaj selekcję zmiennych z wykorzystaniem `SelectFromModel()` w utworzonym `pipeline` w punkcie a). Do funkcji `SelectFromModel()` wykorzystaj model regresji logistycznej a do modelowania wykorzystaj drzewo decyzyjne.\n",
    "\n",
    "c) Przygotuj kolejny `pipeline`, który do wyboru zmiennych zamiast funkcji `SelectFromModel()` wykorzysta funkcję `SequentialFeatureSelector()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SAheart.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "wine_data = datasets.load_wine(as_frame=True)\n",
    "df = wine_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "scaled_df = std_scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit_transform(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ratio = []\n",
    "for num in np.arange(14):\n",
    "  pca = PCA(n_components=num)\n",
    "  pca.fit(scaled_df)\n",
    "  var_ratio.append(np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.lineplot(x = range(scaled_df.shape[1] + 1), y = var_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2\n",
    "----\n",
    "Wczytaj zbiór danych `pima.csv`.\n",
    "\n",
    "a) Podziel zbiór na treningowy i testowy w proporcji 4:1.\n",
    "\n",
    "b) Na zbiorze treningowym wyznacz komponenty uzyskane metodą PCA. Sporządź wykres, który ukazuje jaki procent wariancji jest wyjaśniany przez kolejne komponenty.\n",
    "\n",
    "c) Dopasuj model regresji logistycznej dla danych treningowych pełnych, dla danych po PCA, dla 5 pierwszych komponentów po PCA, dla 2 pierwszych komponentów po PCA.\n",
    "\n",
    "d) Policz dokładność na zbiorze testowym dla każego modelu z punktu c).\n",
    "\n",
    "e) Przygotuj `pipeline` ze wszystkimi krokami dla modelu regresji logistycznej na danych po PCA i policz dokładność na zbiorze testowym.\n",
    "\n",
    "*Wyniki punktu e) powinny być takie same jak dla drugiego modelu z punktu c)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = pd.read_csv(\"pima.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
